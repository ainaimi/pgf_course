---
title: "Implementing the Parametric G Formula with Complex Longitudinal Data"
author: Ashley I. Naimi, PhD 
output:
  tufte::tufte_handout: default
  #tufte::tufte_html: default
---

\noindent {\Large \bf Abstract}

Applied health scientists are increasingly dealing with complex data structures to answer questions about exposure effects and mediation. In such settings, feedback between confounders, exposures, and mediators render standard adjustment methods (regression, restriction, stratification, matching) inappropriate. The parametric g formula—one of three "g" methods—is a versatile tool that can be used to quantify a variety of exposure effects with complex data structures. This workshop will provide a comprehensive overview of the g formula for identifying and estimating causal effects. After a brief introduction to the potential outcomes framework, we will review obstacles to effect estimation and mediation analysis with complex longitudinal data. The g formula will then be introduced with three examples using actual data and software code: (i) a simple simulated analysis that minimizes technical details and emphasizes core concepts; (ii) a mediation analysis setting where interest lies in direct/indirect effects; and (iii) a complex longitudinal data setting where interest lies in estimating the total effect of an exposure measured repeatedly over many months of follow-up. The goal of this workshop will be to enable participants to implement the parametric g formula in a range of settings, to articulate and evaluate key assumptions/limitations, and to implement critical model validation techniques. No prior knowledge of causal modeling, counterfactuals, or g methods is required.

\newpage
\noindent {\Large \bf Outline}
\vskip .25cm
\noindent \underline{Causal Inference}
\begin{itemize}
\item Introduction
\item Complex Longitudinal Data
\item Notation
\item Estimand, Estimator, Estimate
\item Identifiability
\begin{itemize}
    \item[a.] Counterfactual Consistency
    \item[b.] No Interference
    \item[c.] Excheangability
    \item[d.] Positivity
\end{itemize}
\item Statistical Theory Review
\begin{itemize}
    \item[a.] Marginal versus Conditional Effects
    \item[b.] Law of Total Probability
\end{itemize}
\end{itemize}
\noindent \underline{The Parametric G-Formula}
\begin{itemize}
\item Model-Based Standardization (Example 0)
\item Example 1:
\item Example 2:
\item Example 3:
\end{itemize}

\newpage
\onehalfspacing

\noindent {\Large \bf Section 1: Causal Inference}
\noindent {\Large \bf Introduction}

"Causal inference" deals primarily with the formal mechanisms by which we can combine data, assumptions, and models to interpret a correlation (or association) as a causal relation.^[There are a number of excellent introductory books and articles on causal inference in the empirical sciences. Here are a few of my favorites:] The framework by which we define what we mean by "causal relation" or "causal effect" is the **potential outcomes framework**.

A central notion in the potential outcomes framework is the counterfactual. This notion stems from the intuitive and informal practice of interpreting cause-effect relations as **circumstances (e.g., health outcomes) that would have arisen had things (e.g., exposures) been different**.

While this intuition serves an important purpose, it is not sufficient for doing rigorous science. Suppose we ask: "what is the effect of smoking on CVD risk, irrespective of smoking's effect on body weight?" This question seems clear and intiutive. To answer this question, we would do a study in which we collect data, enter these into a computer, perform some calculations, and obtain a number (the "effect").

But there is a problem.^[This problem was articulated by Robins (1987), and I am using the example from his paper.] The calculations performed by the computer are **rigorously defined mathematical objects**. On the other hand, **english language sentences about cause effect relations are ambiguous**.

For example, the "effect of smoking" can mean many different things:
\begin{itemize}
\item All people smoke any tobacco ever versus no people smoke tobacco ever.
\item All people smoke 3 cigarettes per day versus all people smoke 2 cigarettes per day.
\item All people who have smoked any tobacco in the last 15 years cease to smoke any tobacco whatsoever.
\end{itemize}
\noindent Similarly, "irrespective of" can mean a number of things:
\begin{itemize}
\item The effect of smoking on CVD risk that would be observed in a hypothetical world where smoking did not affect body mass?
\item The effect of smoking on CVD risk if everyone were set to "normal" body mass?
\item The effect of smoking on CVD risk if everyone were held at the body mass they had in the month prior to study entry?
\end{itemize}

But the computer does not admit such ambiguity.^[The first computers were called "logical machines"] Depending on several choices, including the data, how variables are coded, and the modeling strategy, the computer is being told which question to answer. There is a lot of potential uncertainty in the space between the English language sentences we use to ask causal questions, and the computer algorithms we use to answer those questions. Causal inference is about clarifying this uncertainty.

\noindent {\Large \bf Complex Longitudinal Data}

This short course is about complex longitudinal data, so let's define that here. We will be dealing with data from a cohort study, individuals sampled from a well-defined target population, and clear study start and stop times (i.e., closed cohort). Data from such a cohort are **longitudinal** when they are measured repeatedly over time.^[Another such form is when data are measured repeatedly across space. We will not be dealing with these data here.]

Different scenarios can lead to longitudinal data:
\begin{itemize}
\item[1.] exposure and covariates do not vary over time, but the study outcome can occur more than once
\item[2.] exposure and covariates vary over time, but the study outcome can only occur once
\item[3.] exposure and covariates vary over time, and the study outcome can occur more than once
\end{itemize}
We will deal with data that from scenario 2 (however, it is not difficult to generalize the logic to scenario 3). 
Repeated exposure, covariate, and/or outcome measurement is what leads to "longitudinal" data. 

But why complex? Repeated measurement over time opens up the possibility of complex causal relations between past and future covariates. Suppose we measure an expsoure twice over follow-up, a covariate once, and the outcome at the end of follow-up (Figure 1). If we can assume that past exposure/covariate values do not affect future exposure/covariate values (usually a very risky assumption), we might not consider these data "complex," becuase we can use many standard methods we already know to analyze these data.
```{r, out.width = "200px",fig.cap="Longitudinal data that might not be considered `complex' because there is no feedback between exposure and covariates.",echo=F}
knitr::include_graphics("F1.pdf")
```
On the other hand, if past exposure/covariates affect future exposure/covariates in such a way that prior exposures or covariates confound future exposures (Figure 2), more advanced analytic techniques are needed. 
```{r, out.width = "200px",fig.cap="The simplest kind of complex longitudinal data. Note that the exposure at time zero affects the covariate at time 1 which affects the exposure at time 1. This feedback leads to confounding of the time 1 expsoure by a covariate that is affected by the prior exposure. Analysis of these data require more general methods to  account for this complex form of confounding.",echo=F}
knitr::include_graphics("F2.pdf")
```
In this short course, we will learn how to use the parametric g formula to account for this type of complex time-varying confounding.

\noindent {\Large \bf Notation}

The building blocks for causal inference are **potential outcomes**. These are conceptually distinct from **observed outcomes**. Potential outcomes are functions of exposures. For a given exposure $x$, we will write the potential outcome as $Y^x$.^[Alternate notation includes: $Y_x$, $Y(x)$, $Y\mid Set(X=x)$, and $Y|do(X=x)$.] **This is interpreted as "the outcome ($Y$) that would be observed if $X$ were set to some value $x$"**. For example, if $X$ is binary [denoted $X \in (0,1)$], then $Y^x$ is the outcome that would be observed if $X=0$ or $X=1$. If we wanted to be specific about the value of $x$, we could write $Y^{x=0}$ or $Y^{x=1}$ (or, more succinctly,  $Y^{0}$ or $Y^{1}$).
```{marginfigure}
**Study Question 1:** Suppose you collect data from a single person and find that they are exposed. Can you interpret their outcome to be the potential outcome that would have been observed had they been exposed?
```

When the exposoure and/or outcome are measured repeatedly over follow-up, notation must account for that. We thus use subscripts to denote when the variable was measured. For example, if the exposure is measured twice, we can denote the first measurement $X_0$ and the second $X_1$. Additionally, we use overbars to denote the history of a variable over follow-up time. For example, $\overline{X}_1$ denotes the set $\{X_0,X_1\}$. More generally, for some arbitrary point over follow-up $m$, $\overline{X}_m$ denotes $\{X_0,X_1,X_2, \ldots X_m\}$. We can then define potential outcomes as a function of these exposure histories: For two exposure measurements, $\overline{X}_j = \{1,1\}$, $Y^{\overline{x}_j = \overline{1}}$ is the outcome that would be observed if $X_0$ were set to $1$ and $X_1$ were set to $1$.

\noindent {\Large \bf Estimand, Estimator, Estimate}

Causal inference starts with a clear idea of the effect of interest (the target causal parameter). To do this, it helps to distinguish between estimands, estimators, and estimates.
```{marginfigure}
**Study Question 2a:** You are familar with the well known odds ratio equation for a $2\times 2$ table: ($ab/cd$). Is this an estimand, estimator, or estimate?
```
```{marginfigure}
**Study Question 2b:** Can you think of another estimator that can be used to quantify the odds ratio?
``` 
The **estimand** is the (mathematical) object we want to quantify. It is, for example, the causal risk difference, risk ratio, or odds ratio for our exposure and outcome of interest. In our smoking CVD example, we might be interested in:

$$ P( Y^{1} = 1) - P( Y^{0} =1 ),\;\;\;\frac{P( Y^{1} = 1)}{P( Y^{0} =1 )},\;\;\; \frac{Odds( Y^{1} = 1)}{ Odds( Y^{0} = 1)}, $$
where $Odds(Y^x = 1) = P(Y^x = 1)/(Y^x = 0)$. There are many others besides these.

The estimand is the object we want to estimate. The **estimator** is an equation that allows us to use our data to quantify the estimand. Suppose, for example, we were explicitly intersted in quantifying the causal risk difference for the relation between smoking and CVD risk. To do this, we have to start by quantifying the associational risk difference, but there are many ways to do this, including:
\begin{itemize}
\item Ordinary least squares
\item Maximum likelihood
\item Method of moments
\end{itemize}

To be specific, let's simulate some hypothetical observational data on the relation between smoking and CVD. Let's look at ordinary least squares and maximum likelihood as estimators:
```{r,echo=F}
expit<-function(z){
  1/(1+exp(-(z)))
}
```
```{r, echo=T,fig.star=T,tidy=F,highlight=T}
### CODE SET 1
set.seed(123)
n<-1e6
confounder<-rbinom(n,1,.5)
smoking<-rbinom(n,1,expit(-2+log(2)*confounder))
CVD<-rbinom(n,1,.1+.05*smoking+.05*confounder)

round(mean(confounder),3)
round(mean(smoking),3)
round(mean(CVD),3)

#OLS
round(coef(lm(CVD~smoking+confounder)),4)

#ML1
round(coef(glm(CVD~smoking+confounder,family=poisson("identity"))),4)

#ML2
round(coef(glm(CVD~smoking+confounder,family=binomial("identity"))),4)
### END CODE SET 1
```
```{r, echo=F}
## for calculations below
set.seed(123)
n<-1e6;confounder<-rbinom(n,1,.5)
smoking<-rbinom(n,1,expit(-2+log(2)*confounder))
CVD<-rbinom(n,1,.1+.05*smoking+.05*confounder)
pC<-round(mean(confounder),3)
ols_RD<-round(coef(lm(CVD~smoking+confounder)),4)
```
In our simple setting with 1 million observations, ordinary least squares and maximum likelihood yielded the same associational risk difference (as expected) even though they are different **estimators**. Finally, the values obtained from each regression approach are our **estimates.**

\noindent {\Large \bf Identifiability}

In our simulation example, we estimated the associational risk difference using three different estimators. However, we can only use the associational risk difference to quantify the causal risk difference if the latter is **identified**. We say that a parameter (e.g., causal risk difference) is identified if we can write it as a function of the observed data. This notion of identifiability is central to causal inference, so I will explain it in detail. 

The causal risk difference is defined as a contrast of potential outcomes, in our case, conditional on $C$:
$$ \psi = P( Y^{1} = 1 \mid C) - P( Y^{0} =1 \mid C ), $$
where $Y_1$, $Y_0$ are the potential CVD outcomes that would be observed if smoking were set to 1 and zero, respectively. On the other hand, the associational risk difference is defined as a contrast of observed outcomes:
$$ \alpha = P( Y = 1 \mid X = 1, C) - P( Y = 1 \mid X = 0, C), $$
where each term in this equation is interpreted as the risk of CVD **among those who had $X=1$**. The causal risk difference is identified if the following equation holds:^[Throughout this course, we will assume that the target parameter of interest is a causal contrast of potential outcomes. Sometimes, the target parameter of interest is an associational contrast, and the assumptions needed are less demanding. See, e.g., Naimi et al (2016) AJE.]
$$ P(Y^x = 1 \mid C) = P(Y = 1 \mid X = x, C) $$
In this equation, the right hand side equation is written entirely in terms of observed data ($Y=1$). The left hand side is a function of unobserved potential outcomes ($Y^x=1$). These functions of observed and potential outcomes will only be equivalent if we can make some assumptions.

The first is **counterfactual consistency**, which states that the potential outcome that would have been observed if we set the exposure to the observed value is the observed outcome.^[While somewhat convoluted, this assumption is about legitimizing the connection between our observational study, and future interventions based on this study. In our observational study, we **see** people with with a certain value of the exposure. In a future intervention, we **set** people to a certain value of the exposure.] Formally, counterfactually consistency states that:
$$\text{ if }X = x\text{ then }Y^x = Y $$
The status of this assumption remains unaffected by the choice of analytic method (e.g., standard regression versus g methods). Rather, this assumption’s validity depends on the nature of the exposure assignment mechanism.

Throughout this short course, we will also assume **no interference**. This assumption states that the potential outcome for any given individual does not depend on the exposure status of another individual. If this assumption were not true, we would have to write the potential outcomes as a function of the expsoure status of multiple individuals. For example, for two different people indexed by $i$ and $j$, we might write: $Y_i^{x_i,x_j}$.^[Together, counterfactual consistency and no interference make up Rubin's stable-unit treatment value assumption (SUTVA).] Notation and methods that account for interference can become very complicated very fast, and we will not consider the impact of interference here.

With counterfactual consistency and no interference, we re-write the above equation as:
$$ P(Y^x = 1 \mid C) = P(Y^x = 1 \mid X = x, C) $$
A third assumption is **exchangeability**, which implies that the potential outcomes under a specific exposure ($Y^x$) is independent of the actual (or observed) exposures $X$. If this holds, then we have: 
$$ P(Y^x = 1 \mid X=x, C) = P(Y^x = 1 \mid C) $$
If there is any confounding, selection, or information bias, the potential outcome under a specific exposure will be associated with the observed exposure, and we cannot remove $X=x$ from the conditioning statement. What this means is that the exposure is predictive of prognosis, independent of it's actual effect on the outcome. 

A final assumption is **positivity**, which requires exposed and unexposed individuals within all levels of the confounder. There are two kinds of positivity violations (non-positivity): structural (or deterministic) and stochastic^[The word **stochastic** is derived from the greek word "to aim," as in "to aim for a target."] (or random). Structural non-positivity occurs when individuals with certain covariate values cannot be exposed. For example, in occupational epidemiology work-status (employed/unemployed in workplace under study) is a confounder, but individuals who leave the workplace can no longer be exposed to a work-based exposure. Alternatively, stochastic non-positivity arises when the sample size is not large enough to populate all confounder strata with individuals in the sample. When faced with positivity violations, methods must be used that are not affected. These include g estimation of a structural nested model, targeted minimum loss-based estimation, and the parametric g formula.

\noindent {\Large \bf Statistical Theory Review}

In learning to use the parametric g formula, it helps to clarify some important statistical concepts. The first is the difference between marginal and conditional effects. In the example outlined in **Code Set 1**, we analyzed data with a binary outcome, exposure, and  confounder using a linear regression model:
$$ P(Y = 1 \mid X, C) = \beta_0+\beta_1X+\beta_2C $$
where $Y$ is CVD status, $X$ is smoking status, and $C$ is the confounder. We used different estimators to quantify the parameters $\beta_0,\beta_1$ and $\beta_2$, and estimated a risk difference of 5 excess CVD events per 100 individuals among smokers relative to non-smokers. Mathematically, the effect is^[We are using the results from the OLS estimator.]: 
$$\hat{P}(Y = 1 \mid X=1,C)-\hat{P}(Y = 1 \mid X=0,C)=\hat{\beta}_1=`r ols_RD[2]`.$$ 

This effect is conditional on $C$, which means that the estimate of $\beta_1$ is the effect of smoking on CVD risk **if we were to hold $C$ constant in the population**. But what if we didn't want to have to interpret it as the effect if we held $C$ constant?^[Don't be mis-lead by the simplicity of this example. It might be clear to you that holding $C$ constant is of little consequence here. This may happen in practice, but will not always be the case] As it turns out, it does not make a difference in this case for two reasons:
\begin{itemize}
\item[1.] There is no interaction between $X$ and $C$, which means the effect of $X$ is the same in each level of $C$.
\item[2.] The model is linear (and thus collapsible), which means that marginal and conditional effects are equivalent.
\end{itemize}

To see that it doesn't matter, we can use the law of total probability to obtain the marginal risk difference that is still adjusted for the confounding effects of $C$. The law of total probability allows us to interpret our risk difference as the effect averaged over the distribution of $C$, instead of the effect if $C$ were held fixed. In our setting, the law of total probability allows us to do this:
\begin{align*}
P(Y=1 \mid X=x) & = \sum_C P(Y = 1 \mid X=x,C) P(C) \\
                & = P(Y = 1 \mid X=x,C=1) P(C=1) \\
                & \hskip .5cm + P(Y = 1 \mid X=x,C=0) P(C=0).
\end{align*}

In effect, the law of total probability simply allows us to take an average of $P(Y = 1 \mid X = x)$, weighted by the proportion of individuals with $C=0$ and $C=1$. To get the marginal risk difference, we apply the equation twice (one for each level of $X$). This equation is simple enough to solve by hand:
\begin{align*}
P(Y = 1 \mid X=1,C=1) & = \hat{\beta}_0 + \hat{\beta}_1\times 1 + \hat{\beta}_2\times 1 \\
                      & = `r ols_RD[1]`+`r ols_RD[2]`+`r ols_RD[3]` = `r ols_RD%*%c(1,1,1)` \\
P(C=1) & = `r pC` \\
P(Y = 1 \mid X=1,C=0) & = \hat{\beta}_0 + \hat{\beta}_1\times 1 + \hat{\beta}_2\times 0 \\
                      & = `r ols_RD[1]`+`r ols_RD[2]` = `r ols_RD%*%c(1,1,0)` \\
P(C=0) & = `r 1-pC`
\end{align*}
The marginally adjusted risk for the exposed is thus: `r round((ols_RD%*%c(1,1,1))*pC + (ols_RD%*%c(1,1,0))*(1-pC),4)`. To calculate the marginally adjusted risk for the unexposed, we carry out the same calculations, but replace all instances of $X=1$ with $X=0$, yielding: `r round((ols_RD%*%c(1,0,1))*pC + (ols_RD%*%c(1,0,0))*(1-pC),4)`. Taking the difference gives a marginally adjusted risk difference of: `r round((ols_RD%*%c(1,1,1))*pC + (ols_RD%*%c(1,1,0))*(1-pC),4)-round((ols_RD%*%c(1,0,1))*pC + (ols_RD%*%c(1,0,0))*(1-pC),4)`, which (as expected) is identical to the conditionally adjusted risk difference.

\noindent {\Large \bf Section 2: The Parametric G Formula}
\noindent {\Large \bf Model-Based Standardization}

The distinction between marginal and conditional effects is important when it comes to the g formula, so let's simulate a more complex example to highlight some important points. Suppose we are in the same setting (CVD, smoking) with the addition of an effect modifier:
```{r, echo=T,fig.star=T,tidy=T,highlight=T,tidy.opts=list(width.cutoff=80)}
### CODE SET 2
set.seed(123)
n<-1e6
confounder<-rbinom(n,1,.5)
phys_act<-rbinom(n,1,.5) #modifier
smoking<-rbinom(n,1,expit(-2+log(2)*confounder))
CVD<-rbinom(n,1,expit(-.25+log(2)*smoking-log(1.5)*phys_act-log(1.25)*smoking*phys_act+log(2)*confounder))

round(mean(confounder),3)
round(mean(smoking),3)
round(mean(phys_act),3)
round(mean(CVD),3)

m1<-coef(glm(CVD~smoking+phys_act+smoking*phys_act+confounder,family=binomial("logit")))
# Effect of smoking among PA = 1
exp(m1%*%c(0,1,0,0,1)) # this code is just an easy way of doing: exp(beta1+beta3)
# Effect of smoking among PA = 0
exp(m1%*%c(0,1,0,0,0)) # this code is just an easy way of doing: exp(beta1)
### END CODE SET 2
```
In this second Code Set, there are two main differences from the previous:
\begin{itemize}
\item[1.] There is an effect modifier (phys\_act) of the relation bewteen smoking and CVD.
\item[2.] The outcome, CVD, was generated from a logistic, instead of a linear model.
\end{itemize}
It should be clear that, in the presence of an effect modifier (let's denote it $Z$), the notion of holding $Z$ constant is much more important (the effect is different depending on the level at which we hold $Z$).

Perhaps less clear is the impact of using the logistic link function. Neuhaus & Jewell (1993) showed that if you add a variable to a logistic regression model that is not associated with either the exposure or the outcome (i.e., not a confounder) the odds ratio will always move away from the null. This phenomenon, which is the result of "non-collapsibility," is why the odds ratio is a somewhat controversial measure of effect (the same is not true for the risk ratio or risk difference).

If we wanted a collapsible measure like the risk ratio, we could fit another model to our data (GLM with binomial distribution and log link), but we could also obtain risk ratios directly from our logistic model. To do this, 










