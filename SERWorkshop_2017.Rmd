---
title: "Implementing the Parametric G Formula with Complex Longitudinal Data"
author: Ashley I. Naimi, PhD 
output:
  #tufte::tufte_handout: default
  tufte::tufte_html: default
---

**Abstract**

Applied health scientists are increasingly dealing with complex data structures to answer questions about exposure effects and mediation. In such settings, feedback between confounders, exposures, and mediators render standard adjustment methods (regression, restriction, stratification, matching) inappropriate. The parametric g formula—one of three "g" methods—is a versatile tool that can be used to quantify a variety of exposure effects with complex data structures.^[The other two g methods are inverse probability weighted marginal structural models, and g estimation of structural nested models] This workshop will provide a comprehensive overview of the g formula for identifying and estimating causal effects. After a brief introduction to the potential outcomes framework, we will review obstacles to effect estimation and mediation analysis with complex longitudinal data. The g formula will then be introduced with three examples using actual data and software code: (i) a simple simulated analysis that minimizes technical details and emphasizes core concepts; (ii) a mediation analysis setting where interest lies in direct/indirect effects; and (iii) a complex longitudinal data setting where interest lies in estimating the total effect of an exposure measured repeatedly over many months of follow-up. The goal of this workshop will be to enable participants to implement the parametric g formula in a range of settings, to articulate and evaluate key assumptions/limitations, and to implement critical model validation techniques. No prior knowledge of causal modeling, counterfactuals, or g methods is required.

\newpage

**Outline**

* [Introduction](#id1) 
* [Notation](#id2)
* [Estimate, Estimand, Estimator](#id3)
* Identifiability
    a. Counterfactual Consistency
    b. Excheangability
    c. Positivity
* The Logic of Causal Inference
* Statistical Theory Review (Short & Pain Free)
* Law of total probability

\newpage
\onehalfspacing


<a id="id1"></a>
**Introduction**

The field of "causal inference" deals primarily with the formal mechanisms by which we can combine data, assumptions, and models to interpret a correlation (or association) as a causal relation.^[There are a number of introductory books and articles on causal inference in the empirical sciences.] The framework by which we define what we mean by  "causal relation" or "causal effect" is the potential outcomes framework.

A central notion in the potential outcomes framework is the counterfactual.^[That which is counter to fact] This notion stems from the intuitive and informal practice of interpreting cause-effect relations as <i>circumstances (e.g., health outcomes) that would have arisen had things (e.g., exposures) been different </i>. 

Suppose we ask: "what is the effect of smoking on CVD risk, irrespective of smoking's effect on body weight?" To answer this question, we would collect data, enter these into a computer, perform some calculations, and obtain a number. We would then interpret this number as the answer to our question.  

But there is a problem.^[This problem was articulated by Robins (1987), and I am using the example from his paper.] The calculations performed by the computer are <b>rigorously defined mathematical objects</b>. On the other hand, <b>english language sentences are ambiguous</b>.

For example, the "effect of smoking" can mean many different things. Consider these options:

* All people smoke any tobacco ever versus no people smoke tobacco ever.
* All people smoke 3 cigarettes per day versus all people smoke 2 cigarettes per day.
* All people who have smoked any tobacco in the last 15 years cease to smoke any tobacco whatsoever.

Similarly, "irrespective of" can also mean a number of things:

* The effect of smoking on CVD risk that would be observed in a hypothetical world where smoking did not affect body mass?
* The effect of smoking on CVD risk if everyone were set to "normal" body mass?
* The effect of smoking on CVD risk if everyone were held at the body mass they had in the month prior to study entry?

But the computer does not admit such ambiguity. Depending on several choices, including what data you collect, what type of modeling strategy you use, how you code your variables, you are telling (perhaps unknowingly) the computer which question to answer. There is therefore a lot of potential uncertainty in the space between the English language sentences we use to ask causal questions, and the computer algorithms that yield answers to those questions. Causal inference is about clarifying this uncertainty.

<a id="id2"></a>
**Notation**

The basic building blocks of the formal approach to causal inference are **potential outcomes**. These are conceptually distinct from (the more familiar) **observed outcomes**. We will get into this in more detail later. Potential outcomes are functions of exposure values. For a given exposure $X$, we will write the potential outcome as $Y_x$.^[Alternate notation includes:$Y^x$, $Y(x)$, $Y\mid Set(X=x)$, and $Y|do(X=x)$.] **This is interpreted as "the outcome ($Y$) that would be observed if $X$ were set to some value $x$"**. For example, if $X \in (0,1)$, then $Y_x$ is the outcome that would be observed if $X=0$ or if $X=1$. If we wanted to be specific about the value of $x$, we could write $Y_{x=0}$ or $Y_{x=1}$ (or, more succinctly,  $Y_{0}$ or $Y_{1}$).^[**Study Question 1:** Suppose you collect data from a single person and find that ]

We will also use conventional statistical notation. We will let capital letters denote random variables and lowercase letters denote their realizations. So, referring back to our example, $X$ refers to the entire distribution of the exposure, whereas $x$ denotes a specific value (e.g., 0 or 1). 

Additionally, we will use greek letters to denote parameters that we need to quantify. In particular, we will distinguish between two types of parameters: target parameter will be denoted with the greek letter $\psi$ ("psi"), and we will separate these from other parameters (termed "nuisance" parameters), which will be denoted using other greek letters (e.g., $\alpha$, $\beta$, $\gamma$, $\theta$).

Target parameters quantify those things that we are specifically interested in (e.g., risk differences or ratios). Nuisance parameters represent quantities that we are not interested in. For example, when we include confounders or the propensity score in a regression model, we are not particularly interested in precisely how they relate to the outcome, but we have to estimate (nuisance) parameters for these covariates.

<a id="id3"></a>
**Estimand, Estimator, Estimate**

Causal inference starts with a clear idea of what effect we want to quantify. To do this, it helps to distinguish between three important concepts: estimands, estimators, and estimates.

```{marginfigure}
**Study Question 2a:** You are familar with the well known odds ratio equation from a $2\times 2$ table ($ab/cd$). Is this an estimand, estimator, or estimate?
```
 
 
```{marginfigure}
**Study Question 2b:** Can you think of another estimator that can be used to quantify the odds ratio? Hint: think regression.
``` 
 
