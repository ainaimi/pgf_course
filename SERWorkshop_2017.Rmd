---
title: "Implementing the Parametric G Formula with Complex Longitudinal Data"
author: Ashley I. Naimi, PhD 
output:
  tufte::tufte_handout: default
  #tufte::tufte_html: default
---

\noindent {\Large \bf Abstract}

Applied health scientists are increasingly dealing with complex data structures to answer questions about exposure effects and mediation. In such settings, feedback between confounders, exposures, and mediators render standard adjustment methods (regression, restriction, stratification, matching) inappropriate. The parametric g formula—one of three "g" methods—is a versatile tool that can be used to quantify a variety of exposure effects with complex data structures. This workshop will provide a comprehensive overview of the g formula for identifying and estimating causal effects. After a brief introduction to the potential outcomes framework, we will review obstacles to effect estimation and mediation analysis with complex longitudinal data. The g formula will then be introduced with three examples using actual data and software code: (i) a simple simulated analysis that minimizes technical details and emphasizes core concepts; (ii) a mediation analysis setting where interest lies in direct/indirect effects; and (iii) a complex longitudinal data setting where interest lies in estimating the total effect of an exposure measured repeatedly over many months of follow-up. The goal of this workshop will be to enable participants to implement the parametric g formula in a range of settings, to articulate and evaluate key assumptions/limitations, and to implement critical model validation techniques. No prior knowledge of causal modeling, counterfactuals, or g methods is required.

\newpage

\noindent {\Large \bf Outline}

Causal Inference
\begin{itemize}
\item Introduction
\item Complex Longitudinal Data
\item Notation
\item Estimand, Estimator, Estimate
\item Identifiability
\begin{itemize}
    \item[a.] Counterfactual Consistency
    \item[b.] Excheangability
    \item[c.] Positivity
\end{itemize}
\item Statistical Theory Review (Short \& Pain Free)
\begin{itemize}
    \item[a.] Marginal versus Conditional Effects
    \item[b.] Law of Total Probability
\end{itemize}
\end{itemize}
The Parametric G-Formula
\begin{itemize}
\item Model-Based Standardization (Example 0)
\item Example 1:
\item Example 2:
\item Example 3:
\end{itemize}

\newpage
\onehalfspacing


\noindent {\Large \bf Introduction}

"Causal inference" deals primarily with the formal mechanisms by which we can combine data, assumptions, and models to interpret a correlation (or association) as a causal relation.^[There are a number of excellent introductory books and articles on causal inference in the empirical sciences. Here are a few of my favorites:] The framework by which we define what we mean by "causal relation" or "causal effect" is the **potential outcomes framework**.

A central notion in the potential outcomes framework is the counterfactual. This notion stems from the intuitive and informal practice of interpreting cause-effect relations as circumstances (e.g., health outcomes) that would have arisen had things (e.g., exposures) been different.

While an intuitive understanding of cause-effect relations serves an important purpose, it is not sufficient for doing rigorous science. Suppose we ask: "what is the effect of smoking on CVD risk, irrespective of smoking's effect on body weight?" This question seems clear and intiutive, and may serve as the basis of an investigation into the effects of smoking. To answer this question, we would do a study in which we collect data, enter these into a computer, perform some calculations, and obtain a number. We would then interpret this number as the answer to our question.

But there is a problem.^[This problem was articulated by Robins (1987), and I am using the example from his paper.] The calculations performed by the computer are **rigorously defined mathematical objects**. On the other hand, **english language sentences are ambiguous**.

For example, the "effect of smoking" can mean many different things. Consider these options:
\begin{itemize}
\item All people smoke any tobacco ever versus no people smoke tobacco ever.
\item All people smoke 3 cigarettes per day versus all people smoke 2 cigarettes per day.
\item All people who have smoked any tobacco in the last 15 years cease to smoke any tobacco whatsoever.
\end{itemize}
Similarly, "irrespective of" can also mean a number of things:
\begin{itemize}
\item The effect of smoking on CVD risk that would be observed in a hypothetical world where smoking did not affect body mass?
\item The effect of smoking on CVD risk if everyone were set to "normal" body mass?
\item The effect of smoking on CVD risk if everyone were held at the body mass they had in the month prior to study entry?
\end{itemize}

But the computer does not admit such ambiguity.^[The first computers were called "logical machines"] Depending on several choices, including what data you collect, how you code your variables, and what type of modeling strategy you use, you are telling (perhaps unknowingly) the computer which question to answer. There is a lot of potential uncertainty in the space between the English language sentences we use to ask causal questions, and the computer algorithms we use to answer those questions. Causal inference is about clarifying this uncertainty.

\noindent {\Large \bf Complex Longitudinal Data}

This short course is about using the g formula to analyze complex longitudinal data, so let's define that here. Throughout this short course, we will be dealing with data that arise from a cohort study, with individuals sampled from a well-defined target population, and with clear study start and stop times (i.e., closed cohort). Data from such a cohort are **longitudinal** when they are measured repeatedly over time.^[Another such form is when data are measured repeatedly across space. We will not be dealing with these data here.]

Different scenarios can lead to longitudinal data. For example:
\begin{itemize}
\item[1.] exposure and covariates do not vary over time, but the study outcome can occur more than once
\item[2.] exposure and covariates vary over time, but the study outcome can only occur once
\item[3.] exposure and covariates vary over time, and the study outcome can occur more than once
\end{itemize}
In our shortcourse, we will be dealing with data that arise from scenario 2 (however, it is not difficult to generalize the logic to scenario 3). 
Repeated exposure, covariate, and/or outcome measurement is what leads to "longitudinal" data. But why complex? Repeated measurement over time opens up the possibility of complex causal relations between past and future covariates. For example, suppose we measure an expsoure twice over follow-up, a covariate once, and the outcome at the end of follow-up (Figure 1). If we can assume that past exposure/covariate values do not affect future exposure/covariate values (usually a very risky assumption), then we might not consider these data "complex," and can use many of the standard methods we already know to analyze these data.
```{r, out.width = "200px",fig.cap="Longitudinal data that might not be considered `complex' because there is no feedback between exposure and covariates.",echo=F}
knitr::include_graphics("F1.pdf")
```
On the other hand, if past exposure/covariate values affect future exposure/covariate values in such a way that prior exposures or covariates confound future exposure relations (Figure 2), more advanced analytic techniques are needed. 
```{r, out.width = "200px",fig.cap="The simplest kind of complex longitudinal data. Note that the exposure at time zero affects the covariate at time 1 which affects the exposure at time 1. This feedback leads to confounding of the time 1 expsoure by a covariate that is affected by the prior exposure. Analysis of these data require more general methods to  account for this complex form of confounding.",echo=F}
knitr::include_graphics("F2.pdf")
```
In this short course, we will learn how to use the parametric g formula to account for this type of complex confounding.

\noindent {\Large \bf Notation}

The basic building blocks for causal inference are **potential outcomes**. These are conceptually distinct from (the more familiar) **observed outcomes**.^[We will get into this in more detail later.] Potential outcomes are functions of exposure values. For a given exposure $X$, we will write the potential outcome as $Y^x$.^[Alternate notation includes: $Y_x$, $Y(x)$, $Y\mid Set(X=x)$, and $Y|do(X=x)$.] **This is interpreted as "the outcome ($Y$) that would be observed if $X$ were set to some value $x$"**. For example, if $X \in (0,1)$, then $Y^x$ is the outcome that would be observed if $X=0$ or $X=1$. If we wanted to be specific about the value of $x$, we could write $Y^{x=0}$ or $Y^{x=1}$ (or, more succinctly,  $Y^{0}$ or $Y^{1}$).
```{marginfigure}
**Study Question 1:** Suppose you collect data from a single person and find that they are exposed. Can you interpret their outcome to be the potential outcome that would have been observed had they been exposed?
```

When the exposoure and/or outcome are measured repeatedly over follow-up, notation must account for that. In such a case, we use subscripts to denote when the variable was measured. For example, if the exposure is measured twice, we can denote the first measurement $X_0$ and the second $X_1$. Additionally, we use overbars to denote the history of a variable over follow-up time. For example, $\overline{X}_1$ denotes the set $\{X_0,X_1\}$. More generally, for some arbitrary point over follow-up $m$, $\overline{X}_m$ denotes $\{X_0,X_1,X_2, \ldots X_m\}$. We can then define potential outcomes as a function of these exposure histories: For two exposure measurements, $\overline{X}_j = \{1,1\}$, $Y^{\overline{x}_j = \overline{1}}$ is the outcome that would be observed if $X_0$ were set to $1$ and $X_1$ were set to $1$.

We will also use conventional statistics notation. We will let capital letters denote random variables and lowercase letters denote their realizations. So, referring back to our example, $X$ refers to the random variable (i.e., entire distribution of the exposure), whereas $x$ denotes a specific value (e.g., 0 or 1). 

Additionally, we will use greek letters to denote parameters that we need to quantify. In particular, we will distinguish between two types of parameters: target causal parameters will be denoted with the greek letter $\psi$ ("psi"), and we will separate these from other parameters, which include "associational" parameters and "nuisance" parameters. These will be denoted using other greek letters (e.g., $\alpha$, $\beta$, $\gamma$, $\theta$).

Target causal parameters quantify those things that we are specifically interested in (e.g., causal risk differences or ratios). They represent contrasts of potential outcomes, and therefore they cannot be estimated directly. Associational parameters also represent differneces or ratios of interest. But they represent contrasts of observed outcomes, and can thus be estimated using data. A major goal in causal inference is to evaluate whether conditions are present that enable us to equate associational and causal parameters. Nuisance parameters represent quantities that we are not interested in. For example, when we include confounders or the propensity score in a regression model, we are not particularly interested in precisely how they relate to the outcome, but we have to estimate (nuisance) parameters for these covariates.

\noindent {\Large \bf Estimand, Estimator, Estimate}

Causal inference first starts with a clear idea of the effect of interest (the target causal parameter). To do this, it helps to distinguish between three important concepts: estimands, estimators, and estimates.
```{marginfigure}
**Study Question 2a:** You are familar with the well known odds ratio equation for a $2\times 2$ table: ($ab/cd$). Is this an estimand, estimator, or estimate?
```
```{marginfigure}
**Study Question 2b:** Can you think of another estimator that can be used to quantify the odds ratio?
``` 
The **estimand** is the (mathematical) object we want to quantify. It is, for example, the causal risk difference, risk ratio, or odds ratio for our exposure and outcome of interest (such as the effect of any versus no smoking (ever) on CVD risk):

$$ P( Y^{1} = 1) - P( Y^{0} =1 ),\;\;\;\frac{P( Y^{1} = 1)}{P( Y^{0} =1 )},\;\;\; \frac{Odds( Y^{1} = 1)}{ Odds( Y^{0} = 1)} $$
There are a wide variety of estimands we can define for a given situation. Below, other estimands often discussed in the causal inference literature are defined.^[For the local average treatment effect (LATE), the subscript on the $X$ denotes the status of an instrumental variable. $X^1$ and $X^0$ are the exposures that would be observed if the instrument were set to 1 or 0, respectively.] Many others can be entertained as well.

<table border="2">
<tr>
<td>Average Causal Effect:</td>
<td>$E(Y^1 - Y^0)$</td>
</tr>
<tr>
<td>Effect of Treatment on the Treated:</td>
<td>$E(Y^1 - Y^0 \mid X=1)$</td>
</tr>
<tr>
<td>Local Average Treatment Effect:</td>
<td>$E(Y^1 - Y^0 \mid X^1-X^0=1)$</td>
</tr>
</table>

With repeated measurements, more complex estimands are possible. For example, we can ask what the effect of an exposure would be if individuals were exposed at some points in time but not others. Alternatively, we can define time-specific effects, and average them over follow-up.^[One example of such time-specific effects include the "blip-function," first defined by Robins (1989), which are encoded via structural nested models] There are a number of ways in which we might define an estimand for a given analysis. One priciple that should guide our choice is: whatever action you would like to implement to improve health in a population should correspond precisely to the chosen estimand. 

The estimand is the object we want to estimate. The **estimator** is an equation that allows us to use our data to quantify the estimand. Suppose, for example, we were explicitly intersted in quantifying the causal risk difference for the relation between smoking and CVD risk. To do this, we have to start by quantifying the associational risk difference, but there are many ways to do this, including:
\begin{itemize}
\item Ordinary least squares
\item Maximum likelihood
\item Method of moments
\item Two stage least squares
\item Many others...
\end{itemize}

To give a specific example, let's simulate some hypothetical observational data on the relation between smoking and CVD. Furthermore, let's keep it simple and look at ordinary least squares and two versions maximum likelihood:
```{r, echo=T,fig.star=T,tidy=F,highlight=T}
### CODE SET 1
# data
expit<-function(z){
  1/(1+exp(-(z)))
}
set.seed(123)
n<-1e6
confounder<-rbinom(n,1,.5)
smoking<-rbinom(n,1,expit(2+log(2)*confounder))
CVD<-rbinom(n,1,.1+.05*smoking+.05*confounder)

#OLS
coef(lm(CVD~smoking+confounder))

#ML1
coef(glm(CVD~smoking+confounder,family=poisson("identity")))

#ML2
coef(glm(CVD~smoking+confounder,family=binomial("identity")))
### END CODE SET 1
```
In our simple setting with 1 million observations, ordinary least squares and maximum likelihood yielded the same associational risk difference (as expected) even though they are different **estimators**. Finally, the values obtained from each regression approach are our **estimates.**

\noindent {\Large \bf Identifiability}

In our simulation example, we estimated the associational risk difference using three different estimators. However, we can only use the associational risk difference to quantify the causal risk difference if the latter is **identified**. We say that a parameter (e.g., causal risk difference) is identified if we can write it as a function of the observed data. This notion of identifiability is central to causal inference, so I will explain it in detail. 

The causal risk difference is defined as a contrast of potential outcomes, in our case, conditional on $C$:
$$ \psi = P( Y^{1} = 1 \mid C) - P( Y^{0} =1 \mid C ), $$
where $Y_1$, $Y_0$ are the potential CVD outcomes that would be observed if smoking were set to 1 and zero, respectively. On the other hand, the associational risk difference is defined as a contrast of observed outcomes:
$$ \alpha = P( Y = 1 \mid X = 1, C) - P( Y = 1 \mid X = 0, C), $$
where each term in this equation is interpreted as the risk of CVD **among those who had $X=1$**. The causal risk difference is identified if the following equation holds:^[Throughout this course, we will assume that the target parameter of interest is a causal contrast of potential outcomes. Sometimes, the target parameter of interest is an associational contrast, and the assumptions needed are less invovled. See, e.g., Naimi et al (2016) AJE.]
$$ P(Y^x = 1 \mid C) = P(Y = 1 \mid X = x, C) $$
In this equation, the right hand side eqution is written entirely in terms of observed data. The left hand side is a function of unobserved potential outcomes. They will only be equivalent if we can make some assumptions.

The first is **counterfactual consistency**. This assumption states that the potential outcome that would have been observed if we set the exposure to the observed value is the same as their observed outcome.^[While somewhat convoluted, this assumption is about legitimizing the connection between our observational study, and future interventions based on this study. In our observational study, we **see** people with with a certain value of the exposure. In a future intervention, we **set** people to a certain value of the exposure.] Formally, counterfactually consistency states that:
$$\text{ if }X = x\text{ then }Y^x = Y $$
The status of this assumption remains unaffected by the choice of analytic method (e.g., standard regression versus g methods). Rather, this assumption’s validity depends on the nature of the exposure assignment mechanism.

Throughout this short course, we will also assume **no interference**. This assumption states that the potential outcome for any given individual does not depend on the exposure status of another individual. If this assumption were not true, we would have to write the potential outcomes as a function of the expsoure status of multiple individuals. For example, for two different people indexed by $i$ and $j$, we might write: $Y^{x_i,x_j}$.^[Together, counterfactual consistency and no interference make up Rubin's stable-unit treatment value assumption (SUTVA).] Notation and methods that account for interference can become very complicated very fast, and we will not consider the impact of interference violations here.

A third assumption is **exchangeability**. Exchangeability implies that the potential outcomes under a specific exposure ($Y^x$) is independent of the actual (or observed) exposures $X$. If this holds, then we have: 
$$ P(Y^x = 1 \mid X=x, C) = P(Y^x = 1 \mid C) $$
If there is any confounding, selection, or information bias, the potential outcome under a specific exposure will be associated with the observed exposure, and we cannot remove $X=x$ from the conditioning statement. What this means is that the exposure is predictive of prognosis, independent of it's actual effect on the outcome. 

A final assumption is **positivity**, which requires exposed and unexposed individuals within all levels of the confounder. There are two kinds of positivity violations (non-positivity): structural (or deterministic) and stochastic^[The word **stochastic** is derived from the greek word "to aim," as in "to aim for a target."] (or random). Structural non-positivity occurs when individuals with certain covariate values cannot be exposed. For example:
\begin{itemize}
\item In occupational epidemiology, when studying the effects of an occupational exposure, work status often acts as a confounder. However, when individuals are no longer at work, they cannot be exposed to the work-based exposure.
\item In reproductive/perinatal epidemiology, when studying the effects of an \emph{in utero} exposure on a post-gestational outcome, the unit of observation (fetus/infant) can no longer be exposed once delivered. However, one will often want to adjust for the effects of being delivered earlier/later in gestation.
\item In social epidemiology, race and wealth/income are strongly correlated such that one might encounter populations in which, for example, there are no wealthy black individuals, and/or no impoverished white individuals. 
\end{itemize}

Alternatively, stochastic non-positivity arises when the sample size is not large enough to populate all confounder strata with individuals in the sample. When faced with positivity violations, methods must be used that are not affected. These include g estimation of a structural nested model, targeted minimum loss-based estimation, and the parametric g formula.

\noindent {\Large \bf Statistical Theory Review}

In learning to use the parametric g formula, it helps to clarify some important statistical concepts. The first is the difference between marginal and conditional effects. In the example outlined in **Code Set 1**, we analyzed data with a binary outcome, exposure, and  confounder using a linear regression model:
$$ E(Y = 1 \mid X, C) = \beta_0+\beta_1X+\beta_2C $$
where $Y$ is CVD status, $X$ is smoking status, and $C$ is the confounder. We used different estimators to quantify the parameters $\beta_0,\beta_1$ and $\beta_2$, and estimated a risk difference of 5 excess CVD events per 100 indivduals among smokers relative to non-smokers ($\hat{\beta}_1=0.05$). 

This effect is conditional on $C$, which means that we must interpret the estimate of $\beta_1$ as the effect of smoking on CDV risk **if we were to hold $C$ constant in the population**. 


