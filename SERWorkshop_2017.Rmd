---
title: "Introduction to the Parametric G Formula"
author: Ashley I. Naimi, PhD 
output:
  tufte::tufte_handout: default
  #tufte::tufte_html: default
bibliography: ref_main_v4.bib
---

\noindent {\Large \bf Abstract}

Applied health scientists are increasingly dealing with complex data structures to answer questions about exposure effects and mediation. In such settings, feedback between confounders, exposures, and mediators render standard adjustment methods (regression, restriction, stratification, matching) inappropriate. The parametric g formula—one of three "g" methods—is a versatile tool that can be used to quantify a variety of exposure effects with complex data structures. This workshop will provide a comprehensive overview of the g formula for identifying and estimating causal effects. After a brief introduction to the potential outcomes framework, we will review obstacles to effect estimation and mediation analysis with complex longitudinal data. The g formula will then be introduced with three examples using actual data and software code: (i) a simple simulated analysis that minimizes technical details and emphasizes core concepts; (ii) a mediation analysis setting where interest lies in direct/indirect effects; and (iii) a complex longitudinal data setting where interest lies in estimating the total effect of an exposure measured repeatedly over many months of follow-up. The goal of this workshop will be to enable participants to implement the parametric g formula in a range of settings, to articulate and evaluate key assumptions/limitations, and to implement critical model validation techniques. No prior knowledge of causal modeling, counterfactuals, or g methods is required.

\newpage
\noindent {\Large \bf Outline}
\vskip .25cm
\noindent \underline{Causal Inference}
\begin{itemize}
\item Introduction
\item Complex Longitudinal Data
\item Notation
\item Estimand, Estimator, Estimate
\item Identifiability
\begin{itemize}
    \item[a.] Counterfactual Consistency
    \item[b.] No Interference
    \item[c.] Excheangability
    \item[d.] Positivity
\end{itemize}
\item Statistical Review
\begin{itemize}
    \item[a.] Marginal versus Conditional Effects
    \item[b.] Law of Total Probability
\end{itemize}
\end{itemize}
\noindent \underline{The Parametric G-Formula}
\begin{itemize}
\item Model-Based Standardization (Example 0)
\item Example 1:
\item Example 2:
\item Example 3:
\end{itemize}

\newpage
\onehalfspacing

\noindent {\Large \bf \underline{Causal Inference}}

\noindent {\Large \bf Introduction}

"Causal inference" deals primarily with the formal mechanisms by which we can combine data, assumptions, and models to interpret a correlation (or association) as a causal relation.^[There are a number of excellent introductory books and articles on causal inference in the empirical sciences. Here are a few of my favorites:] The framework by which we define what we mean by "causal relation" or "causal effect" is the **potential outcomes framework**.

A central notion in the potential outcomes framework is the counterfactual. This notion stems from the intuitive and informal practice of interpreting cause-effect relations as **circumstances (e.g., health outcomes) that would have arisen had things (e.g., exposures) been different**.

While this intuition serves an important purpose, it is not sufficient for doing rigorous science. Suppose we ask: "what is the effect of smoking on CVD risk, irrespective of smoking's effect on body weight?" This question seems clear and intiutive. To answer this question, we would do a study in which we collect data, enter these into a computer, perform some calculations, and obtain a number (the "effect").

But there is a problem.^[This problem was articulated by Robins (1987), and I am using the example from his paper.] The calculations performed by the computer are **rigorously defined mathematical objects**. On the other hand, **english language sentences about cause effect relations are ambiguous**. For example, the "effect of smoking" can mean many different things:

\begin{itemize}
\item All people smoke any tobacco ever versus no people smoke tobacco ever.
\item All people smoke 3 cigarettes per day versus all people smoke 2 cigarettes per day.
\item All people who have smoked any tobacco in the last 15 years cease to smoke any tobacco whatsoever.
\end{itemize}
\noindent Similarly, "irrespective of" can mean a number of things:
\begin{itemize}
\item The effect of smoking on CVD risk that would be observed in a hypothetical world where smoking did not affect body mass?
\item The effect of smoking on CVD risk if everyone were set to "normal" body mass?
\item The effect of smoking on CVD risk if everyone were held at the body mass they had in the month prior to study entry?
\end{itemize}

But the computer does not admit such ambiguity.^[The first computers were called "logical machines"] Depending on several choices, including the data, how variables are coded, and the modeling strategy, the computer is being told which question to answer. There is a lot of potential uncertainty in the space between the English language sentences we use to ask causal questions, and the computer algorithms we use to answer those questions. Causal inference is about clarifying this uncertainty.

\noindent {\Large \bf Complex Longitudinal Data}

This short course is about complex longitudinal data, so let's define that here. We will be dealing with data from a cohort study, individuals sampled from a well-defined target population, and clear study start and stop times (i.e., closed cohort). Data from such a cohort are **longitudinal** when they are measured repeatedly over time.^[Another such form is when data are measured repeatedly across space. We will not be dealing with these data here.]

Different scenarios can lead to longitudinal data:
\begin{itemize}
\item[1.] exposure and covariates do not vary over time, but the study outcome can occur more than once
\item[2.] exposure and covariates vary over time, but the study outcome can only occur once
\item[3.] exposure and covariates vary over time, and the study outcome can occur more than once
\end{itemize}
We will deal with data that from scenario 2 (however, it is not difficult to generalize the logic to scenario 3). 
Repeated exposure, covariate, and/or outcome measurement is what leads to "longitudinal" data. But why complex? 

Repeated measurement over time opens up the possibility of complex causal relations between past and future covariates. Suppose we measure an expsoure twice over follow-up, a covariate once, and the outcome at the end of follow-up (Figure 1). If we can assume that past exposure/covariate values do not affect future exposure/covariate values (usually a very risky assumption), we might not consider these data "complex," becuase we can use many standard methods we already know to analyze these data.
```{r, out.width = "200px",fig.cap="Longitudinal data that might not be considered `complex' because there is no feedback between exposure and covariates.",echo=F}
knitr::include_graphics("F1.pdf")
```
On the other hand, if past exposure/covariates affect future exposure/covariates in such a way that prior exposures or covariates confound future exposures (Figure 2), more advanced analytic techniques are needed. 
```{r, out.width = "200px",fig.cap="The simplest kind of complex longitudinal data. Note that the exposure at time zero affects the covariate at time 1 which affects the exposure at time 1. This feedback leads to confounding of the time 1 expsoure by a covariate that is affected by the prior exposure. Analysis of these data require more general methods to  account for this complex form of confounding.",echo=F}
knitr::include_graphics("F2.pdf")
```
In this short course, we will learn how to use the parametric g formula to account for this type of complex time-varying confounding.

\noindent {\Large \bf Notation}

The building blocks for causal inference are **potential outcomes**. These are conceptually distinct from **observed outcomes**. Potential outcomes are functions of exposures. For a given exposure $x$, we will write the potential outcome as $Y^x$.^[Alternate notation includes: $Y_x$, $Y(x)$, $Y\mid Set(X=x)$, and $Y|do(X=x)$.] **This is interpreted as "the outcome ($Y$) that would be observed if $X$ were set to some value $x$"**. For example, if $X$ is binary [denoted $X \in (0,1)$], then $Y^x$ is the outcome that would be observed if $X=0$ or $X=1$. If we wanted to be specific about the value of $x$, we could write $Y^{x=0}$ or $Y^{x=1}$ (or, more succinctly,  $Y^{0}$ or $Y^{1}$).
```{marginfigure}
**Study Question 1:** Suppose you collect data from a single person and find that they are exposed. Can you interpret their outcome to be the potential outcome that would have been observed had they been exposed?
```

When the exposoure and/or outcome are measured repeatedly over follow-up, notation must account for that. We thus use subscripts to denote when the variable was measured. For example, if the exposure is measured twice, we can denote the first measurement $X_0$ and the second $X_1$. Additionally, we use overbars to denote the history of a variable over follow-up time. For example, $\overline{X}_1$ denotes the set $\{X_0,X_1\}$. More generally, for some arbitrary point over follow-up $m$, $\overline{X}_m$ denotes $\{X_0,X_1,X_2, \ldots X_m\}$. We can then define potential outcomes as a function of these exposure histories: For two exposure measurements, $\overline{X}_j = \{1,1\}$, $Y^{\overline{x}_j = \overline{1}}$ is the outcome that would be observed if $X_0$ were set to $1$ and $X_1$ were set to $1$.

\noindent {\Large \bf Estimand, Estimator, Estimate}

Causal inference starts with a clear idea of the effect of interest (the target causal parameter). To do this, it helps to distinguish between estimands, estimators, and estimates.
```{marginfigure}
**Study Question 2a:** You are familar with the well known odds ratio equation for a $2\times 2$ table: ($ab/cd$). Is this an estimand, estimator, or estimate?
```
```{marginfigure}
**Study Question 2b:** Can you think of another estimator that can be used to quantify the odds ratio?
``` 
The **estimand** is the (mathematical) object we want to quantify. It is, for example, the causal risk difference, risk ratio, or odds ratio for our exposure and outcome of interest. In our smoking CVD example, we might be interested in:

$$ P( Y^{1} = 1) - P( Y^{0} =1 ),\;\;\;\frac{P( Y^{1} = 1)}{P( Y^{0} =1 )},\;\;\; \frac{Odds( Y^{1} = 1)}{ Odds( Y^{0} = 1)}, $$
where $Odds(Y^x = 1) = P(Y^x = 1)/(Y^x = 0)$. There are many others besides these.

The estimand is the object we want to estimate. The **estimator** is an equation that allows us to use our data to quantify the estimand. Suppose, for example, we were explicitly intersted in quantifying the causal risk difference for the relation between smoking and CVD risk. To do this, we have to start by quantifying the associational risk difference, but there are many ways to do this, including ordinary least squares, maximum likelihood, or the method of moments.

To be specific, let's simulate some hypothetical observational data on the relation between smoking and CVD. Let's look at ordinary least squares and maximum likelihood as estimators:
```{r,echo=F}
expit<-function(z){
  1/(1+exp(-(z)))
}
```
```{r, echo=T,fig.star=T,tidy=F,highlight=T}
### CODE SET 1
set.seed(123)
n<-1e6
confounder<-rbinom(n,1,.5)
smoking<-rbinom(n,1,expit(-2+log(2)*confounder))
CVD<-rbinom(n,1,.1+.05*smoking+.05*confounder)

round(mean(confounder),3)
round(mean(smoking),3)
round(mean(CVD),3)

#OLS
round(coef(lm(CVD~smoking+confounder)),4)

#ML1
round(coef(glm(CVD~smoking+confounder,family=poisson("identity"))),4)

#ML2
round(coef(glm(CVD~smoking+confounder,family=binomial("identity"))),4)
### END CODE SET 1
```
```{r, echo=F}
## for calculations below
set.seed(123)
n<-1e6;confounder<-rbinom(n,1,.5)
smoking<-rbinom(n,1,expit(-2+log(2)*confounder))
CVD<-rbinom(n,1,.1+.05*smoking+.05*confounder)
pC<-round(mean(confounder),3)
ols_RD<-round(coef(lm(CVD~smoking+confounder)),4)
```
In our simple setting with 1 million observations, ordinary least squares and maximum likelihood yielded the same associational risk difference (as expected) even though they are different **estimators**. Finally, the values obtained from each regression approach are our **estimates.**

\noindent {\Large \bf Identifiability}

In our simulation example, we estimated the associational risk difference using three different estimators. Estimating associations is really all we can do with empirical data. But we want to use the associational risk difference to quantify the causal risk difference. We can only do so if the causal risk difference is **identified**. A parameter (e.g., causal risk difference) is identified if we can write it as a function of the observed data.

The causal risk difference is defined as a contrast of potential outcomes. Referring back to our simulated example, we want to estimate the causal risk difference conditional on $C$:
$$ P( Y^{1} = 1 \mid C) - P( Y^{0} =1 \mid C ), $$
where $Y^1$, $Y^0$ are the potential CVD outcomes that would be observed if smoking were set to 1 and 0, respectively. On the other hand, the associational risk difference is defined as a contrast of observed outcomes:
$$ P( Y = 1 \mid X = 1, C) - P( Y = 1 \mid X = 0, C), $$
where each term in this equation is interpreted as the risk of CVD **among those who had $X=x$**. The causal risk difference is identified if the following equation holds:^[Throughout this course, we will assume that the target parameter of interest is a causal contrast of potential outcomes. Sometimes, the target parameter of interest is an associational contrast, and the assumptions needed are less demanding. See, e.g., @Naimi2016c.]
$$ P(Y^x = 1 \mid C) = P(Y = 1 \mid X = x, C) $$
which says that the risk of CVD that would be observed if everyone were set to $X=x$ is equal to the risk of CVD that we observe among those with $X=x$. In this equation, the right hand side equation is written entirely in terms of observed data ($Y=1$). The left hand side is a function of unobserved potential outcomes ($Y^x=1$). This equivalence will only hold if we can make some assumptions.

The first is **counterfactual consistency**, which states that the potential outcome that would be observed if we set the exposure to the observed value is the observed outcome.^[While somewhat convoluted, this assumption is about legitimizing the connection between our observational study, and future interventions based on this study. In our observational study, we **see** people with with a certain value of the exposure. In a future intervention, we **set** people to a certain value of the exposure.] Formally, counterfactually consistency states that:
$$\text{ if }X = x\text{ then }Y^x = Y $$
The status of this assumption remains unaffected by the choice of analytic method (e.g., standard regression versus g methods). Rather, this assumption’s validity depends on the nature of the exposure assignment mechanism.

We must also assume **no interference**, which states that the potential outcome for any given individual does not depend on the exposure status of another individual. If this assumption were not true, we would have to write the potential outcomes as a function of the expsoure status of multiple individuals. For example, for two different people indexed by $i$ and $j$, we might write: $Y_i^{x_i,x_j}$.^[Together, counterfactual consistency and no interference make up Rubin's stable-unit treatment value assumption (SUTVA).] Notation and methods that account for interference can become very complicated very fast, and we will not consider the impact of interference here.

Together, counterfactual consistency and no interference allow us to make some progress in writing the potential risk $P(Y^x = 1 \mid C)$ as a function of the observed risk $P(Y = 1 \mid X=x, C)$. Specifically, by counterfactual consistency and no interference, we can do the following:
$$ P( Y = 1 \mid X = x, C) = P(Y^x = 1 \mid X = x, C) $$
A third assumption is **exchangeability**, which implies that the potential outcomes under a specific exposure ($Y^x$) are independent of the observed exposures $X$. If this holds, then we have: 
$$ P(Y^x = 1 \mid X=x, C) = P(Y^x = 1 \mid C) $$
If there is any confounding, selection, or information bias, the potential outcome under a specific exposure will be associated with the observed exposure, and we cannot remove $X=x$ from the conditioning statement. What this means is that the exposure is predictive of prognosis, independent of it's actual effect on the outcome. 

Although it seems that we have successfully written the potential risk as a function of the observed data, we are in need of one more assumption. **Positivity**^[Also known as the experimental treatment assignment assumption.] requires exposed and unexposed individuals within all levels of the confounder. There are two kinds of positivity violations (non-positivity): structural (or deterministic) and stochastic^[The word **stochastic** is derived from the greek word "to aim," as in "to aim for a target."] (or random). Structural non-positivity occurs when individuals with certain covariate values cannot be exposed. For example, in occupational epidemiology work-status (employed/unemployed in workplace under study) is a confounder, but individuals who leave the workplace can no longer be exposed to a work-based exposure. Alternatively, stochastic non-positivity arises when the sample size is not large enough to populate all confounder strata with individuals in the sample. When faced with positivity violations, methods must be used that are not affected. These include g estimation of a structural nested model, targeted minimum loss-based estimation, and the parametric g formula.

\noindent {\Large \bf Statistical Theory Review}

In learning to use the parametric g formula, it helps to clarify some important statistical concepts. The first is the difference between marginal and conditional effects. In the example outlined in **Code Set 1**, we analyzed data with a binary outcome, exposure, and  confounder using a linear regression model:
$$ P(Y = 1 \mid X, C) = \beta_0 + \beta_1 X + \beta_2 C $$
where $Y$ is CVD status, $X$ is smoking status, and $C$ is the confounder. We used different estimators to quantify the parameters $\beta_0,\beta_1$ and $\beta_2$, and estimated a risk difference of 5 excess CVD events per 100 individuals among smokers relative to non-smokers. Expressed mathematically, the effect is:^[We are using the results from the OLS estimator.] 
$$\hat{P}(Y = 1 \mid X=1,C)-\hat{P}(Y = 1 \mid X=0,C)=\hat{\beta}_1=`r ols_RD[2]`.$$ 

This effect is conditional on $C$, which means that the estimate of $\beta_1$ is the effect of smoking on CVD risk **if we were to hold $C$ constant in the population**. But what if we didn't want to have to interpret it as the effect if we held $C$ constant?^[Don't be mis-lead by the simplicity of this example. It might be clear to you that holding $C$ constant is of little consequence here. This may happen in practice, but will not always be the case] As it turns out, it does not make a difference in this case for two reasons:
\begin{itemize}
\item[1.] There is no interaction between $X$ and $C$, which means the effect of $X$ is the same in each level of $C$.
\item[2.] The model is linear (and thus collapsible), which means that marginal and conditional effects are equivalent.
\end{itemize}

To see that it doesn't matter, we can use the law of total probability to obtain the marginal risk difference that is still adjusted for the confounding effects of $C$. We can then interpret our risk difference as the effect averaged over the distribution of $C$, instead of the effect if $C$ were held fixed.^[More familiar to epidemiologists is the notion of standardizing the effect to the distribution of $C$ in some population. Using the law of total probability as we are allows us to standardize our effect to the total population.] In our setting, the law of total probability allows us to do this:
\begin{align*}
P(Y=1 \mid X=x) & = \sum_c P(Y = 1 \mid X=x,C) P(C) \\
                & = P(Y = 1 \mid X=x,C=1) P(C=1) \\
                & \hskip .5cm + P(Y = 1 \mid X=x,C=0) P(C=0).
\end{align*}

In effect, the law of total probability simply allows us to take an average of $P(Y = 1 \mid X = x)$, weighted by the proportion of individuals with $C=0$ and $C=1$. To get the marginal risk difference, we apply the equation twice (one for each level of $X$), which is simple enough to do by hand. For the exposed, we have:
\begin{align*}
P(Y = 1 \mid X=1,C=1) & = \hat{\beta}_0 + \hat{\beta}_1\times 1 + \hat{\beta}_2\times 1 \\
                      & = `r ols_RD[1]`+`r ols_RD[2]`+`r ols_RD[3]` = `r ols_RD%*%c(1,1,1)` \\
P(C=1) & = `r pC` \\
P(Y = 1 \mid X=1,C=0) & = \hat{\beta}_0 + \hat{\beta}_1\times 1 + \hat{\beta}_2\times 0 \\
                      & = `r ols_RD[1]`+`r ols_RD[2]` = `r ols_RD%*%c(1,1,0)` \\
P(C=0) & = `r 1-pC`
\end{align*}
The marginally adjusted risk for the exposed is thus: `r round((ols_RD%*%c(1,1,1))*pC + (ols_RD%*%c(1,1,0))*(1-pC),4)`. To calculate the marginally adjusted risk for the unexposed, we carry out the same calculations, but replace all instances of $X=1$ with $X=0$, yielding: `r round((ols_RD%*%c(1,0,1))*pC + (ols_RD%*%c(1,0,0))*(1-pC),4)`. Taking the difference gives a marginally adjusted risk difference of: `r round((ols_RD%*%c(1,1,1))*pC + (ols_RD%*%c(1,1,0))*(1-pC),4)-round((ols_RD%*%c(1,0,1))*pC + (ols_RD%*%c(1,0,0))*(1-pC),4)`, which (as expected) is identical to the conditionally adjusted risk difference.

\noindent {\Large \bf \underline{The Parametric G Formula}}

\noindent {\Large \bf Example 0: Model-Based Standardization}

The law of total probability is central to the g formula, so let's use it with a difference example. Suppose we are in the same setting (CVD, smoking):
```{r, echo=T,fig.star=T,tidy=T,highlight=T,tidy.opts=list(width.cutoff=80)}
### CODE SET 2
set.seed(123)
n<-1e6
confounder<-rbinom(n,1,.5)
smoking<-rbinom(n,1,expit(-2+log(2)*confounder))
CVD<-rbinom(n,1,expit(-.4+log(2)*smoking+log(2)*confounder))

round(mean(confounder),3)
round(mean(smoking),3)
round(mean(CVD),3)

logistic_model<-glm(CVD~smoking+confounder,family=binomial("logit"))
# Effect of smoking
OR_c<-round(exp(coef(logistic_model)%*%c(0,1,0)),2) # this code is just an easy way of doing: exp(beta1)
OR_c

logbinomial_model<-glm(CVD~smoking+confounder,family=binomial("log"))
RR_c<-round(exp(coef(logbinomial_model)%*%c(0,1,0)),2) # this code is just an easy way of doing: exp(beta1)
RR_c

linear_model<-glm(CVD~smoking+confounder,family=binomial("identity"))
RD_c<-round(coef(linear_model)%*%c(0,1,0),2) # this code is just an easy way of doing: exp(beta1)
RD_c

### END CODE SET 2
```
The main difference between this and the previous code set is that the outcome is simulated and analyzed from a logistic model, with 50% CVD proportion.^[This was to demonstrate non-collapsibility, not to strive for realism.] In this example, the **conditionally adjusted odds ratio** for the effect of smoking on CVD is `r OR_c`.

Let's use the law of total probability to obtain a marginally adjusted effect estimate from the logistic model in Code Set 2. As in the first example, our objective is to obtain standardized risks from the logistic model of CVD for smokers and non-smokers. We can then use these risks to quantify differences, risk ratios, or odds ratios. 

Instead of computing these risks by hand as we did for Code Set 1, we can implement the law of total probability via model predictions (which would be much closer to how we would do this in more complex practical settings). To do this, we need to model each varaible that we will marginalize over (in our case, the confounder), as well as the outcome:
```{r, echo=T,fig.star=T,tidy=T,highlight=T,tidy.opts=list(width.cutoff=80)}
### CODE SET 3
# fit the models
logistic_model<-glm(CVD~smoking+confounder,family=binomial("logit"))
confounder_model<-glm(confounder~1,family=binomial("logit"))
```
\noindent We can then obtain predicted probabilities of CVD and the confounder under smoking = 1 and smoking = 0:
```{r, echo=T,fig.star=T,tidy=T,highlight=T,tidy.opts=list(width.cutoff=80)}
# predict probabilities for CVD and the confounder under smoking=1
new_dat<-data.frame(smoking=1,confounder)
pCVD1<-predict(logistic_model,new_dat,type="response")
pC1<-predict(confounder_model,new_dat,type="response")

# predict probabilities for CVD and the confounder under smoking=0
new_dat<-data.frame(smoking=0,confounder)
pCVD2<-predict(logistic_model,new_dat,type="response")
pC2<-predict(confounder_model,new_dat,type="response")
```
\noindent To take a weighted average, we can multiply the predicted probabilities for smoking=0 and smoking=1, separately:
```{r, echo=T,fig.star=T,tidy=T,highlight=T,tidy.opts=list(width.cutoff=80)}
# multiply the predicted probabilities
p1<-pCVD1*pC1
p2<-pCVD2*pC2
```
\noindent take the average of their products, and contrast them to obtain risk differences, risk ratios, or odds ratios:
```{r, echo=T,fig.star=T,tidy=T,highlight=T,tidy.opts=list(width.cutoff=80)}
#Risk Difference
RD_m<-round(mean(p1)-mean(p2),3)
#Risk Ratio
RR_m<-round(mean(p1)/mean(p2),2)
#Odds Ratio
OR_m<-round((mean(p1)/(1-mean(p1)))/(mean(p2)/(1-mean(p2))),2)
### END CODE SET 3
```

Notice that while the conditionally adjusted odds ratio is `r OR_c`, the marginally adjusted odds ratio is `r OR_m`. This difference between the conditionally and marginally adjusted odds ratios is due to non-collapsibility.^[@Neuhaus1993 showed that if you add a variable to a logistic regression model that is not associated with either the exposure or the outcome (i.e., not a confounder) the odds ratio will always move away from the null. This is becuase the odds ratio is "non-collapsible". If the variable added to the model is a confounder, then the exposure association will change for two reasons: a reduction in confounding and non-collapsibility. This one reason that the odds ratio is a controversial measure of effect (the same is not true for the risk ratio or risk difference).]

Let's review some key features of how we marginally standardized the odds ratio in the second example. First, we fit a logistic regression model for the outcome, and an intercept only logistic regression model for the confounder. Second, we obtained predictions from the outcome model under two scenarios: smoking = 1 and smoking = 0. We also obtained predictions from the confounder model under the "natural" scenario (i.e., simple predictions). Third, we combined these predictions (multiplied) to obtain the marginally standardized risks of CVD. Finally, we contrasted the marginally standardized risks to obtain risk differences, risk ratios, and odds ratios. Becuase we used regression models to obtain standardized risks, we call this procedure model-based standardization.

These key features are the basic elements needed to implement the parametric g formula. However, in the first two examples we used data that was neither complex or longitudinal.

\noindent {\Large \bf Example 1: ART effect on CD4 Count (Simulated)}

# References